# 数据库设计

[TOC]



## 1设计范式

### 1.1游戏服务器

#### 1.1.1特点

- 延迟敏感

  游戏中用户会产生大量操作，都要求实时进行反馈，一般不能忍受超过1s以上；

- 强交互

  在游戏中，玩家的实时交互非常频繁；

- 数据集中

  游戏是一个几乎完全虚拟的世界，在游戏中的数据，实际上很少能在其他系统中产生价值，对数据的分布式需求较低，数据的集中度非常高；

- 读多写少

  游戏中的数据遵循一条规则：“变化越快的数据，重要性越低”；出于对安全性的考虑，一般对游戏数据的修改只能通过游戏服务器，禁止其他系统对数据的修改；出于降低延迟的考虑，一般在登录时会把数据一次性载入内存，在内存中修改，定时/定量同步到数据库；

#### 1.1.2设计思路

由于游戏与其它行业的区别（低延迟，强交互），在游戏服务器上使用通用的缓存/数据库系统会面临以下问题：

- 延迟过大

  对于通用型缓存/数据库系统(redis, memcache...)，每次数据的存取操作耗时是直接对内存操作的数倍～数十倍，对于一些延迟敏感型的游戏（战斗，竞技）来说这种延迟令人无法接受；

所以，游戏到目前为止，并没有通用的缓存方案，一般都是针对某款/某类游戏进行专有定制；

一个优秀的游戏缓存系统应该包含以下特点：

- 自动对内存中缓存的数据进行管理

  不需要业务逻辑来对数据进行管理操作，系统自动维护数据，减少业务开发的负担；

- 自动进行数据落地与容灾管理

  游戏过程中有大量数据产生，并且都集中在内存中，一旦游戏进程崩溃，就会造成巨大的损失，需要一套高效的容灾机制来降低损失；

- 良好的编程易用性

  最好是能直接存取代码中的对象，实现代码数据与内存数据的自动转换；避免额外添加一套对数据结构的描述（如sql），节省开发时间；

### 1.2电子商务

#### 1.2.1特点

- 延迟不敏感

  对操作的延迟要求低，用户操作频率低；

- 弱交互

  一般电商业务基于浏览器/app，用户之间的实时交互要求较低；

- 数据分散

  电商数据一般在多个不同的业务系统中产生，数据的集中性较低，对于数据的分布式需求比游戏要求高；

- 读多写多

  由于电商行业的特殊性，会产生大量的数据，同时需要对数据进行大量修改；



## 2分表分库

TODO



## 3通用缓存系统

### 3.1缓存系统评判指标

- 强一致性(Strict Consistency)
  1. 任何一次读都能读到某个数据的最近一次写的数据（最终一致性）
  2. 系统中的所有进程，看到的操作顺序，都和全局时钟下的顺序一致
- 弱一致性(Weak Consistency)
  1. 数据更新后，如果能容忍后续的访问只能访问到部分或者全部访问不到
- 并发量
  1. 单表单库并发读写
  2. 多表多库并发读写

### 3.2数据一致性解决方案

#### 3.2.1方案一 先删缓存再更新数据库

![cache_proj1](res/cache_proj1.png)

- 写操作

  1. 先删除缓存数据
  2. 更新数据库数据，避免脏数据
  3. 异步将数据刷回缓存

- 读操作

  1. 读缓存数据
  2. 如果缓存找不到数据，去读数据库
  3. 异步将数据刷回缓存

优点：

1. 整个流程非常简单，适用于低并发场景

缺点：

1. 容灾不足

   "写1"时删除缓存失败怎么处理；如果继续执行，那一直读的缓存数据不就是错误数据了？

2. 并发问题

   - 写写并发

     如果多个服务同时更新数据库，无法保证操作顺序，会存在相互覆盖问题

   - 读写并发

     如果消费者A的读操作与消费者B的写操作同时进行；流程如下：

     1. B删除缓存数据v1

     2. A读缓存数据，缓存找不到数据

     3. A读数据库数据，数据库返回数据v1

     4. B将数据库的数据v1更新为v2

     5. B将v2刷回缓存

     6. A将v1刷回缓存

        此时A的“脏数据”会覆盖B已经修改过的缓存数据，此时缓存中还是v1，此方案无法保证最终一致性。

     示意图如下：

     ```sequence
     Title: 读写并发异常示意
     B->缓存: 1.删除缓存数据v1
     A->缓存: 2.读缓存数据
     缓存-->A: 缓存找不到数据
     A->数据库: 读数据库数据
     数据库-->A: 返回数据v1
     B->数据库: 更新数据库数据v2
     B->缓存: 更新缓存数据v2
     A->缓存: 更新缓存数据v1
     ```

总结：

使用场景：并发量，一致性要求都不是很高的情况

由于其刷新缓存策略可能会失败，失败之后缓存数据一直处于错误状态，它并不能保证数据的最终一致性，也不能保证并发读写的安全性。

#### 3.2.2方案二 先删缓存再更新数据库同时引入binlog机制

![cache_proj2](res/cache_proj2.png)

- 写操作
  1. 删除缓存数据
  2. 更新数据库
  3. 监听数据库的binlog，找到需要刷新的数据
  4. 读数据库数据
  5. 把读到的数据写入缓存
- 读操作
  1. 读缓存数据
  2. 如果缓存找不到数据，去读数据库
  3. 异步将数据刷回缓存

优点：

1. “写4”或“写5”如果失败，可以进行日志回放，再次重试
2. 无论“写1”是否成功，后面都会刷新缓存

缺点：

1. 并发问题

   对于缓存中没有数据的情况无效：

   - 读的时候，缓存中的数据已经失效，此时又发生了更新
   - 数据更新的时候，缓存中的数据已经失效，此时又发生了更新

总结：

适用场景：业务简单，读写QPS比较低的情况。

binlog用来刷新缓存，由于其天然的顺序性，做同步操作很有优势。但是当不同行，表，库的binlog同时消费时，binglog并不是时间串行的。

使用案例：

- [阿里巴巴开源组件：canal](https://github.com/alibaba/canal)
- [linkedin开源组件：databus](https://github.com/linkedin/databus)

#### 3.2.3方案三 在方案二的基础上引入MQ串行化机制

![cache_proj3](res/cache_proj3.png)

- 写操作
  1. 先删除缓存
  2. 更新数据库
  3. 监听数据库的binlog，分析出需要刷新的数据标识
  4. 将数据标识push给MQ
  5. 从MQ中消费数据标识，根据数据标识从数据库读取数据
  6. 更新缓存
- 读操作
  1. 先读缓存
  2. 没读到缓存，再去读数据库
  3. 把需要更新的数据标识push给MQ
  4. 从MQ中消费数据标识，根据数据标识从读数据库读取数据
  5. 更新缓存

优点：

1. 容灾完备

   - "写1"删除缓存失败：后面会覆盖
   - "写4"写MQ失败：Databus或Canal都会重试
   - "写5"或"写6"失败：MQ支持重新消费
   - "读3"写MQ失败：不会影响到缓存，下次还是会来读数据库

2. 串行化

   借助MQ的机制，让读和写操作都串行化，不存在并发问题

缺点：

1. "写5"每次都会去读数据库，会加大数据库压力（每次写也就加多1次读，问题不大）

#### 3.2.4方案四 在方案三的基础上添加标记

![cache_proj4](res/cache_proj4.png)

- 写操作
  1. 把要修改的数据做个标记，标识“正在被修改”，同时设定标记的有效时间；如果标记失败，放弃本次修改。
  2. 更新数据库。
  3. 删除缓存。
  4. 监听数据库的binlog，分析出需要刷新的数据标识。
  5. 将数据标识push给MQ。
  6. 从MQ中消费数据标识，根据数据标识从数据库读取数据。
  7. 更新缓存。
- 读操作
  1. 检查数据标记，如果被标记，直接读数据库，读完结束。
  2. 如果没有被标记，先读缓存。
  3. 如果缓存没有，再读数据库。
  4. 把需要更新的数据标识push给MQ
  5. 从MQ中消费数据标识，根据数据标识从读数据库读取数据
  6. 更新缓存

### 3.3缓存系统组件

- Redis
- ...

### 3.4缓存系统常见问题

#### 3.4.1缓存穿透

缓存和数据库中都没有的数据，用户还是源源不断的发起请求，导致每次请求都会到数据库，从而压垮数据库

解决方案：

1. 业务层校验

   对用户发过来的请求进行检查，有问题直接拦截

2. 对于查找不到的数据，在缓存中将其值设置为NULL，并设置较短的过期时间

3. 布隆过滤器

   利用布隆过滤器的特性，判断数据存不存在，存在才去查找

#### 3.4.2缓存击穿

缓存中一个热点key在失效的同时，大量的请求过来，这些请求全部到达数据库，压垮数据库

解决方案：

1. 设置热点数据永不过期

   对于频繁读取的数据设置其永不过期

2. 定时更新过期时间

   在过期时间到来之前，去给它重新设置（续命）

3. 互斥锁

   利用一个缓存中的数据值来作为锁标记，锁住时设置为1或true，释放锁时设置为0或false（记得设置过期，放置锁死）；要想修改数据库，得先拿到这个锁标记。

#### 3.4.3 缓存雪崩

缓存中混存的数据大面积失效或者缓存宕机，导致大量请求直接到数据库，压垮数据库。

解决方案：

1. 数据过期时间不要太密集，不要全都排到一起失效

2. 数据预热

   对于即将来临的大量请求，提前缓存到缓存中

3. 保证缓存高可用

   做集群



## 参考

- [20万人同时在线的游戏数据库要如何设计](https://cloud.tencent.com/developer/article/1071145)
- [游戏数据库设计经验](https://blog.csdn.net/pengdali/article/details/95376038)
- [电商系统设计之订单](https://segmentfault.com/a/1190000015784047)
- [缓存与数据库一致性系列-01](https://blog.kido.site/2018/12/01/db-and-cache-01/)
- [缓存与数据库一致性系列-02](https://blog.kido.site/2018/12/07/db-and-cache-02/)
- [cannal与databus的对比](https://www.cnblogs.com/xunshao/p/9762377.html)
- [最全面的缓存架构设计（全是干货）](https://blog.csdn.net/zjttlance/article/details/80234341)
- [大型分布式系统中的缓存架构](https://www.cnblogs.com/panchanggui/p/9503666.html)
- [漫谈Web缓存架构](https://www.cnblogs.com/neal-ke/p/8966971.html)

