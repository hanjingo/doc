# 第十章 多处理机操作系统

[TOC]



## 10.1 多处理机系统的基本概念

### 10.1.1 多处理机系统的引入

引入多处理机系统的原因：

- CPU的时钟频率问题
- 增加系统吞吐量
- 节省投资
- 提高系统可靠性

### 10.1.2 多处理机系统的类型

1. 紧密耦合MPS和松弛耦合MPS

   - 紧密耦合（Tightly Coupled）MPS的实现方式：

     1. 多处理器共享主存储器系统和I/O设备。
     2. 将多处理器与多个存储器分别相连，或将主存储器划分为若干个能被独立访问的存储器模块，每个处理器对应一个存储器或存储器模块。

   - 松散耦合（Loosely Coupled）MPS的实现方式：

     通过通道或通信线路来实现多台计算机之间的互连。

2. 对称多处理器系统和非对称多处理器系统

   根据系统中所用处理器的相同与否，可将MPS分为如下两类：

   - `对称多处理器系统SMPS（Symmetric Multiprocessor System）` 
   - `非对称多处理器系统ASMPS（Asymmetric Multiprocessor System）`



## 10.2 多处理机系统的结构

### 10.2.1 UMA多处理机系统的结构

`统一内存访问（Uniform Memory Access，UMA）` 可以分为以下结构：

- 基于单总线的SMP结构

  ![10_1](res/10_1.png)

  *基于总线的SMP结构*

  缺点：

  - 可伸缩性有限；
  - 系统中所有CPU对存储器的访问，都需要通过总线进行，多个CPU可能同时需要对总线进行访问，形成了对总线资源的争夺。

- 使用多层总线的SMP结构

- 使用单级交叉开关的系统结构

  ![10_2](res/10_2.png)

  *使用交叉开关的UMA多处理机系统*

  使用交叉开关的UMA多处理机系统具有如下特征：

  1. 节点之间的连接：交叉开关一般是构成一个$N \times N$的阵列，但在每一行和每一列中，都同时只能有一个交叉点开关处于“开”状态，从而它同时只能接通$N$对结点。
  2. CPU结点与存储器之间的连接：每个存储器模块同时只允许一个CPU结点访问，故每一列只能接通一个交叉点开关，但是为了支持并行存储访问，每一行同时可以接通多个交叉开关。
  3. 交叉开关的成本为$N^2$，$N$为端口数，限制了它在大规模系统中的应用。

- 使用多级交换网格的系统结构

  ![10_3](res/10_3.png)

  *使用多级交换网络的SMP结构示意图*

### 10.2.2 NUMA多处理机系统结构

1. NUMA结构和特点

   `非统一内存访问（Nonuniform-Memory-Access，NUMA）` 所有共享存储器在物理上是分布式的，在逻辑上是连续的，所有这些存储器的集合就是全局地址空间，系统中的每一个CPU都可以访问整个系统的内存，但访问时所用的指令不同。

   ![10_4](res/10_4.png)

   *NUMA结构的多处理机系统*

   NUMA存储器分层：

   1. 本地存储器
   2. 群内共享存储器
   3. 全局共享存储器或其他节点存储器

2. CC-NUMA构造方法

   对于系统中每个CPU所拥有的若干高速缓存块目录表，对每个高速缓存块的位置和状态进行记录和维护。每个CPU的每条访问存储器单元已存在于某个高速缓存块中，并进行相应操作。

   ![10_5](res/10_5.png)

   *CC-NUMA构造方法*

   **注意：远程内存访问由于访问远地内存的延时远远超过本地内存，因此当CPU数量增加时，系统性能无法线性增加**



## 10.3 多处理机操作系统的特征与分类

### 10.3.1 多处理机操作系统的特征

1. 并行性
2. 分布性
   - 任务的分布
   - 资源的分布
   - 控制的分布
3. 机间的通信和同步性
4. 可重构性

### 10.3.2 多处理机操作系统的功能

1. 进程管理
   - 进程同步
   - 进程通信
   - 进程调度
2. 存储器管理
   - 地址变换机构
   - 访问冲突仲裁机构
   - 数据一致性机制
3. 文件管理
   - 集中式
   - 分散式
   - 分布式
4. 系统重构

### 10.3.3 多处理机操作系统的类型

1. 主从式（master-slave）

   由从处理机向主处理机提交任务申请，该请求被捕获后送至主处理机，而后等待主处理机发回应答；主处理机收到请求后中断当前任务，对该请求进行识别和判断，并转入执行相应的处理程序，然后将适合的任务分配个发出请求的从处理机。

   | 优点       | 缺点                           |
   | ---------- | ------------------------------ |
   | - 易于实现 | - 资源利用率低<br>- 安全性较差 |

2. 独立监督式（separate supervisor System）

   每个处理机上都有自己的管理程序，并拥有各自的专用资源，所配置的操作系统也具有与单机操作系统类似的功能，以服务自身的需要，及管理自己的资源和为进程分配任务。

   | 优点                     | 缺点                                                 |
   | ------------------------ | ---------------------------------------------------- |
   | - 自主性强<br>- 可靠性高 | - 实现复杂<br>- 存储空间开销大<br>- 处理机负载不平衡 |

3. 浮动监督式（floating supervisor Control Mode）

   所有处理机组成一个处理机池，每台处理机都可对整个系统中的任何一台I/O设备进行控制，以及对任何一个存储模块进行访问，这些处理机由操作系统统一进行管理，在某段时间内可以指定任何一台（或多台）处理机作为系统的控制处理机，即所谓“主”处理机（或组），由它（或它们）运行操作系统程序，负责全面管理功能；根据需要“主”处理机的身份可以从一台处理机切换到另一台处理机。

   | 优点                                   | 缺点       |
   | -------------------------------------- | ---------- |
   | - 高灵活性<br>- 高可靠性<br>- 负载均衡 | - 实现复杂 |



## 10.4 进程同步

### 10.4.1 集中式与分布式同步方式

1. 中心同步实体

   满足以下条件的`同步实体（Synchronizing Entity）`称为中心同步实体：

   - 具有唯一名字，并且为彼此必须同步的所有进程所知道；
   - 在任何时刻，这些进程中的任何一个都可以访问该同步实体。

2. 集中式同步机构

   基于中心同步实体所构成的所有同步机构被称为集中式同步机构。

3. 集中式与分布式同步算法

   - 集中式同步算法

     1. 对于多个进程需要同时访问共享资源或进行通信时，仅由中心控制结点做出判断，选择一个进程执行；
     2. 判定所需要的全部信息都集中在中心控制结点。

     缺点：

     - 可靠性差
     - 易形成瓶颈

   - 分布式同步算法

     1. 所有结点具有相同的信息；
     2. 所有结点仅基于本地信息作出判断；
     3. 为了做出最后的判定，所有的结点担负相同的指责；
     4. 为了做出最后的判定，所有的结点要付出同样的工作量；
     5. 通常一个结点发生故障，不会导致整个系统的崩溃。

4. 中心进程方式

   在系统中设置一个协调进程（中心进程），其它进程访问与退出临界区都需要向协调进程申请。

### 10.4.2 自旋锁（spin lock）

在总线上设置一个自旋锁，该锁最多只能被一个内核进程持有。当一个内核进程需要使用总线，对某个存储单元进行读写访问时，先请求自旋锁，以获得对总线的使用权。如果该锁被占用，那么这个进程就会一直进行“旋转”，循环测试锁的状态，直到自旋锁重新可用。如果锁未被占用，请求该锁的内核进程便能立刻得到它，并继续执行，直到完成对指定存储单元的读写操作后，释放该锁。

自旋锁与信号量的主要差别：

- 自旋锁可避免调用进程阻塞
- 应用于对总线资源的竞争，效率远高于信号量机制

自旋锁的类型：

- `普通自旋锁` 若锁可用，则将自旋锁变量置为0，否则为1；该类自旋锁的使用不会影响当前处理机的中断状态，一般在临界区的代码在禁止中断情况下使用，或者不能被中断处理程序所执行。
- `读写自旋锁` 允许多个读者同时以只读的方式访问相同的共享数据结构，但是当一个写者正在更新这个数据结构时，不允许其它读者或写者访问。这类自旋锁较普通自旋锁允许更高的并发性，只要有一个读者拥有，写者就不能强占。每个读写自旋锁包括一个$n$位的读者计数和一个解锁标记。一般而言，在写者等待的情况下，新进的读者较写者更容易抢占该锁。
- `大读者自旋锁` 获取读锁时只需要对本地读写锁进行加锁，开销很小；获取写锁时则必须锁住所有CPU上的读锁，代价较高。

### 10.4.3 读-拷贝-修改锁和二进制指数补偿算法

1. 读-拷贝-修改锁（RCU）的引入

   当写进程要往某文件中写入数据时，它先读该文件，将文件的内容拷贝到一个副本上，以后只对副本上的内容进行修改；修改完成后，在适当时候再将修改完后的文件全部写回去。

2. RCU（Read-Copy-Update）锁

   RCU锁用来解决读者-写者问题；对于被RCU保护的共享文件（数据结构），无论读者和写者，都是以读的方式对其进行访问的，对于读者而言，不需要获得任何锁就可以访问它，对于写者而言，在访问它时，先制作该文件的一个副本，只对副本上的内容进行修改，然后使用一个回调（callback）机制，即向系统中一个称为垃圾收集器的机构注册一个回调函数。在适当时机，由垃圾收集器调用写者注册的回调函数，把指向原来数据的指针重新指向新的被修改的数据，完成最后的数据释放或修改操作。

3. 写回时机

   最好是在所有读者都已完成自己的读任务后再将修改后的文件写回。

4. RCU锁的优点

   - 读者不会被阻塞
   - 无需为共享文件（数据）设置同步机构

### 10.4.4 二进制指数补偿算法和待锁CPU等待队列机构

1. 二进制指数补偿算法

   为每一个CPU对锁进行测试的TSL指令设置一个指令延迟执行时间，使该指令的下次执行是在该延迟执行时间设定的时间后进行，其延迟时间是按照一个TSL指令执行周期的二进制指数方式增加。

   采用二进制指数补偿算法可以明显降低总线上的数据流量，原因如下：

   - 可以将短时间内各CPU对锁的需求，在时间上进行不同程度的延迟，增加测试的成功率，减少各CPU对锁的测试次数；
   - 在锁不空闲时，也很大程度地减少各CPU对其进行测试的频率。

   缺点：

   - 锁被释放时，不能及时地发现锁的空闲，造成浪费。

2. 待锁CPU等待队列机构

   为每一个CPU配置一个用于测试的私有锁变量和一个记录待锁CPU的待锁清单，存放在其私有的告诉缓存中。当多个CPU需要互斥访问某个共享数据结构时，如果该结构已被占用，则为第一个未获得锁的CPU分配一个锁变量，并且将之附在占用该共享数据结构CPU的待锁清单末尾；再为第二个未获得锁的CPU也分配一个锁变量，并且将之附在待锁清单中第一个待锁CPU的后面；...；

### 10.4.5 定序机构

1. 时间邮戳定序机构（Timestamp Ordering Mechanism）

   - 对所有的特殊事件，如资源请求，通信等，加印上时间邮戳；
   - 对每一种特殊事件，只能使用唯一的时间邮戳；
   - 根据事件上的时间邮戳，定义所有事件的全序。

2. 事件计数（Event Counts）同步机构

   对于事件计数，有下面几种操作：

   - `await(E, V)` 每当进程要进入临界区之前，先执行await操作，如果$E < V$，将执行进程插入到EQ队列，并重新调度，否则进程继续执行；
   
     ```c
     await(E, V) {
         if (E < V) {
             i = EP;
             stop();
             i->status = "block";
             i->sdata = EQ;
             insert(EQ, i);
             scheduler();
         }
         else continue;
     }
     ```
   
   - `advance(E)` 每当进程退出临界区时，应执行$advance(E)$操作，使E值增1。如果EQ队列不空，则进一步检查队首进程的V值，若$E = V$，则唤醒该进程。
   
     ```c
     advance(eventcount E) {
         E = E + 1;
         if (EQ <> NIL) {
             V = inspect(EQ, 1);
             if (E == V) wakeup(EQ, 1);
         }
     }
     ```
   
     一个进程执行临时区的操作序列为：
   
     ```c
     await(E, V);
     Access the critical resources;
     advance(E);
     ```
   
   - `read(E)` 返回E的当前值，提供给进程参考，以决定是否要转去处理其它事件。如果设计得当，允许await, read和advance这三个操作，在同一事件上并发执行，但对定序器必须互斥使用。

### 10.4.6 面包房算法

利用事件排序的方法对要求访问临界资源的全部事件进行排序，按照FCFS次序对事件进行处理。该算法的基本假设如下：

- 系统由$N$个结点组成，每个结点只有一个进程，仅负责控制一种临界资源，并处理那些同时到达的请求。
- 每个进程保持一个队列，用来记录本结点最近收到的消息，以及本结点自己产生的消息。
- 消息分为请求消息，应答消息和撤销消息三种，每个进程队列中的请求消息根据事件时序排序，队列初始为空。
- 进程$P_i$发送的请求消息形如$request(T_i, i)$，其中$T_i = C_i$，是进程$P_i$发送此消息时对应的逻辑时钟值，$i$代表消息内容。

算法描述如下：

1. 当进程$P_i$请求资源时，它把请求消息$request(T_i, i)$排在自己的请求队列中，同时也把该消息发送给系统中的其它进程；
2. 当进程$P_j$接收到外来消息$request(T_i, i)$后，发送回答消息$reply(T_j, j)$，并把$request(T_i, i)$放入自己的请求队列；应当说明，若进程$P_j$在收到$request(T_i, i)$前已提出对同一资源的访问请求，那么其时间戳应比$(T_i, i)$小；
3. 若满足下述条件，则允许进程$P_i$访问该资源（即允许进入临界区）：
   - $P_i$自身请求访问该资源的消息已处于请求队列的最前面；
   - $P_i$已收到从所有其它进程发来的回答消息，这些回答消息的时间戳均晚于$(T_i, i)$。
4. 为了释放该资源，$P_i$从自己的队列中撤销请求消息，并发送一个打上时间戳的释放消息release给其它进程；
5. 当进程$P_j$收到$P_i$的release消息后，它撤销自己队列中的原$P_i$的$request(T_i, i)$消息。

### 10.4.7 令牌环算法

将所有进程组成一个`逻辑环（Logical Ring）`，系统中设置一个象征存取权力的Token，在进程所组成的逻辑环中，不断地循环传递，获得令牌的进程，才有权力进入临界区，访问共享资源。

由于Token只有一个，任何时刻，只有一个进程能够持有令牌，因此能实现对共享资源的互斥访问。



## 10.5 多处理机系统的进程调度

### 10.5.1 评价调度性能的若干因素

1. 任务流时间

   把完成任务所需要的时间定义为任务流时间；

   ![10_6](res/10_6.png)

   *任务流和调度流示意图*

2. 调度流时间

   多处理机系统中，任务可以被分配到多个处理机上去运行；一个调度流时间时系统中所有处理机上的任务流时间的总和。

3. 平均流

   平均流等于调度流时间除以任务数。平均流时间越小，表示任务占用处理机与存储器等资源的时间越短，这不仅反应了系统资源利用率高，而且还可以降低任务的机时费用，有效地提高了系统的吞吐量。

4. 处理机利用率

   处理机的利用率等于该处理机上任务流之和除以最大有效时间单位。

5. 加速比

   加速比等于各处理机忙时间之和除以并行工作时间。加速比用于度量多处理机系统的加速程度，处理机台数越多，调度流时间越大，与单机相比其完成任务的速度越快，但是较少的处理机可减少成本。对于给定的任务，占用较少的处理机可腾出更多的处理机，用于其它任务，从而使系统的总体性能得到提高。

6. 吞吐率

   吞吐率是单位时间内系统完成的任务数，可以用任务流的最小完成时间来度量系统的吞吐率，吞吐率的高低与调度算法的效率有关。

### 10.5.2 进程分配方式

1. 对称多处理机系统中的进程分配方式

   - `静态分配（Static Assigenment）方式` 一个进程从开始执行直至完成，都被固定地分配到一个处理器上执行；
   - `动态分配（Dynamic Assigenment）方式` 在系统中设置一个公共的就绪队列，系统中的所有就绪进程都被放在该队列中；分配进程时，可将继承分配到任何一个处理器上。
   
   |          | 优点                                                         | 缺点                               |
   | -------- | ------------------------------------------------------------ | ---------------------------------- |
   | 静态分配 | - 开销小                                                     | - 会使各处理器忙闲不均             |
   | 动态分配 | - 避免各处理器忙闲不均<br>- 不会增加**紧密耦合系统**的调度开销 | - 会增加**松散耦合系统**的调度开销 |
   
2. 非对称MPS中的进程分配方式

   对于非堆成MPS，OS的核心部分驻留在一台主机上（Master），而从机（Slave）上只是用户程序，进程调度只由主机执行。

   | 优点           | 缺点                                       |
   | -------------- | ------------------------------------------ |
   | - 系统处理简单 | - 可靠性低<br>- 系统瓶颈受主机处理能力限制 |

### 10.5.3 进程（线程）调度方式

1. 自调度（Self-Scheduling）方式

   在系统中设置有一个公共的进程或线程就绪队列，所有的处理器在空闲时，都可自己到该队列中取得一进程（或线程）来运行。

   | 优点                                                         | 缺点                                     |
   | ------------------------------------------------------------ | ---------------------------------------- |
   | - 容易将单机环境下的调度机制移植到多机环境<br>- 避免忙闲不均，有利于提高处理机的利用率 | - 瓶颈问题<br>- 低效性<br>- 线程切换频繁 |

2. 成组调度（Gang Scheduling）方式

   将一个进程中的一组线程分配到一组处理器上执行；成组调度时为应用程序分配处理器时间的方式：

   - 面向所有应用程序平均分配处理器时间

   - 面向所有线程平均分配处理机时间

   ![10_7](res/10_7.png)

   *两种分配处理机时间的方法*
   
   | 优点                                                         | 缺点 |
   | ------------------------------------------------------------ | ---- |
   | - 减少进程（线程）切换，提升效率<br>- 显著减少调度频率，降低调度开销 |      |
   
2. 专用处理机分配（Dedicated Processor Assigement）方式

   在一个应用程序的执行期间，专门为该应用程序分配一组处理机，每个线程一个处理机，直至该应用程序完成。

   适用于并发程度相当高的多处理机环境，理由如下：

   - 对于数十个乃至数百个处理机的高度并行的系统，单处理机的利用率不是非常重要；
   - 每个进程（线程）专用一个处理机，可以完全避免切换，提升效率。
   
   ![10_8](res/10_8.png)
   
   *线程数对加速比的影响*
   
2. 动态调度

   该调度方式允许进程在执行期间动态地改变其线程的数目，操作系统的调度责任主要限于处理机的分配，并遵循以下原则：

   - 空闲则分配
   - 新作业绝对优先
   - 保持等待
   - 释放即分配

### 10.5.3 死锁

1. 死锁的类型

   - 资源死锁
   - 通信死锁

2. 死锁的检测和解除

   - 集中式检测

     检测方式：

     1. 当资源图中加入或删除一条弧时，相应的变动消息就发送给检测进程；
     2. 每个进程将新添加或删除的弧的信息周期性地发送给检测进程；
     3. 检测进程主动去请求更新信息。

   - 分布式检测

     在每个消息上附加逻辑时钟，并依次对请求和释放资源的消息进行排队，在一个进程对某资源操作前，必须先向所有其它进程发送请求消息，在获得这些进程的响应信息后，才把请求资源的消息发送给该资源的管理进程。



## 10.6 网络操作系统

### 10.6.1 网络及网络体系结构

1. 计算机网络的组成

   - 通信子网
   - 资源子网
   - 网络协议

2. 网络协议

   - 语义
   - 语法
   - 时序

3. 互连网协议IPv4和IPv6

   - IPv4
   - IPv6

4. 传输层协议TCP和UDP

   - 传输控制协议TCP
   - 用户数据报协议UDP

5. 网络体系结构

   OSI/RM（Open System Interconnection/Reference Model）网络体系分层：

   ![10_9](res/10_9.png)

   - 物理层（Physical Layer）
   - 数据链路层（Data Link Layer）
   - 网络层（Network Layer）
   - 传输层（Transport Layer）
   - 会晤层（Session Layer）
   - 表示层（Presentation Layer）
   - 应用层（Application Layer）

### 10.6.2 网络操作系统及其分类

1. 网络操作系统及其特征
   - 硬件独立性
   - 接口一致性
   - 资源透明性
   - 系统可靠性
   - 执行并行性
2. 网络操作系统的分类
   - 对等模式（peer-to-peer model）
   - 工作站/服务器模式（Workstation/Server model）
   - 客户/服务器模式（Client/Server model）
   - 浏览器/服务器模式（Browser/Server model）

### 10.6.3 网络操作系统的功能

1. 数据通信
   - 连接的建立与拆除
   - 报文的分解与组装
   - 传输控制
   - 流量控制
   - 差错的检测与纠正
2. 应用互操作
   - 信息的互通性
   - 信息的“互用性”
3. 网络管理
   - 网络管理的目标
     - 增强网络的可用性
     - 提高网络的运行质量
     - 提高网络的资源利用率
     - 保障网络数据的安全性
     - 提高网络的社会和经济效益
   - 网络管理的功能
     - 配置管理
     - 故障管理
     - 性能管理
     - 安全管理
     - 计费管理



## 10.7 分布式文件系统

### 10.7.1 分布式系统

1. 分布式系统的特征
   - 分布性
   - 透明性
   - 同一性
   - 全局性
2. 分布式系统的优点
   - 计算能力强
   - 易于实现共享
   - 方便通信
   - 可靠性高
   - 可扩展性好
3. 分布式操作系统
   - 通信管理功能
   - 资源管理功能
   - 进程管理功能

### 10.7.2 分布式文件系统的实现方式和基本要求

1. DFS的实现方式
   - 共享文件系统方式（shared file system approach）
   - 共享磁盘方式（shared disk approach）
2. 基本要求
   - 透明性
   - 高性能和高可靠性
   - 容错性
   - 安全性
   - 一致性

### 10.7.3 命名及共享语义

1. 命名方案

   - 集合主机名和本地名对文件命名，保证在整个系统范围的唯一性。
   - 将若干台服务器中的远程目录，加载到客户机的本地目录中。
   - 全局统一命名，即系统采用统一的全局命名结构，每个文件和目录使用唯一的命名。

2. 共享语义

   实现多客户机共享文件的方法：
   
   - UNIX语义
   - 回话语义
   - 不允许更新文件
   - 事务处理
   
3. 租赁协议
   
   租赁协议实际上是一个多读者单写者的机制，即同一时间在同一文件上可以允许多个客户机进行读操作，但对于客户机的写操作，同一时间只允许一个客户机进行，进行读写操作的客户机只能互斥进行。
   

### 10.7.4 远程文件访问和缓存

1.  缓存和远程服务的比较

   - 使用缓存时，大量的远程访问可转为对本地的缓存访问，因而获得的服务速度与本地访问的一样快。
   - 使用缓存时，服务器的负载和网络通信量都减少了，扩充能力加强了。而在使用远程服务器方法时，每次远程访问都是跨国网络处理的，明显增加了网络通信量和服务器负载，引起性能下降。
   - 缓存时，就网络总开销而言，与远程服务针对个别请求一系列应答的传输开销相比，缓存采用以整个文件或文件的若干页面这样的大批数据传输方式时，开销还是要低很多。
   - 缓存的主要缺点是一致性问题。在针对不经常写入的访问模式中，缓存方法是优越的；但在频繁写的情况下，用于解决一致性问题的机制反而导致存在性能，网络通信量和服务器负载等方面的大量开销。
   - 在用缓存作为远程访问方法的系统中，仿真集中式系统的共享语义是困难的。使用远程服务时，服务器将所有访问串行化，因此能够实现任何集中的共享语义。
   - 机器间的接口不同，远程服务方式仅仅是本地文件系统接口在网络上的扩展，机器间的接口就是本地客户机和文件系统之间的接口。而缓存方式中，数据是在服务器和客户机之间整体传输，机器间的接口与上级的用户接口是不同的。

2. 缓存的粒度和位置

   - 缓存的粒度
   - 缓存的位置

3. 缓存的更新

   写回策略：

   1. 直接写
   2. 延迟写
   3. 驱逐时写
   4. 周期性写
   5. 关闭时写

4. 数据一致性

   一致性检查方法：

   - 客户机发起
   - 服务器发起

### 10.7.5 容错

1. 无状态服务和有状态服务

   - `有状态服务（stateful file service）` 一个服务器对某个客户机提供数据服务时，缓存了该客户机的有关信息，该服务器称为有状态服务器。
   - `无状态服务（stateless file service）` 当服务器对某个客户机提供数据服务时，没有缓存该客户机的有关信息，该服务器称为无状态服务器。

2. 容错性

   有关DFS的容错性环境，定义了三种文件属性：

   - `可恢复性` 当对某个文件的操作失败，或由客户中断此操作时，如果文件能转换到原来的一致性状态，则说明此文件是可恢复的；
   - `坚定性` 如果当某个存储器崩溃或存储介质损坏时某个文件能保证完好，则说明此文件是坚定的；
   - `可用性` 如果无论何时一旦需要就可访问，甚至在某个机器和存储器崩溃，或者在发生通信失效的情况下，某个文件仍然可被访问，则称这种文件是可用的。

3. 可用性与文件复制

   文件复制是保证可用性的一个冗余措施，通过对每个文件在多个服务器上的独立备份，增加系统的可靠性。

